{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rua9b1lIlWPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suLptmDUlXpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f97ad00c-29dd-4c6d-f7a6-2e03294ca730"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('ndrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ndrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5zg8rqEmNa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a015595-7aaa-4073-ffb4-274ea2eec4b2"
      },
      "source": [
        "cd /content/ndrive/My Drive/isb"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/ndrive/My Drive/isb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqUKiEebmvtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "ef692d73-fcb4-4b40-fffc-5eacf435535c"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import nltk\n",
        "nltk.download()\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from keras.preprocessing.text import Tokenizer as tokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> stopwords\n",
            "    Downloading package stopwords to /root/nltk_data...\n",
            "      Unzipping corpora/stopwords.zip.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> wordnet\n",
            "    Downloading package wordnet to /root/nltk_data...\n",
            "      Unzipping corpora/wordnet.zip.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDCOtFStoD_H",
        "colab_type": "text"
      },
      "source": [
        "**Solution**:Write a code to match names from list1 (provided in the file: name matching -list1.xlsx) to list2 (name matching – list2.xlsx). The names in list1 have multiple variations of a name and map to exactly one name in list2. Also, provide an accuracy measure of the names matched.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfk6Ls3toDQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel(\"name matching - list1.xlsx\")\n",
        "def cleanupList1Data(df):\n",
        "  df.assignee = df.assignee.str.partition(' (')\n",
        "  df.assignee = df.sort_values(\"assignee\")\n",
        "  df.assignee = df.assignee.str.replace(',','')\n",
        "  df.assignee = df.assignee.str.replace('.','')\n",
        "  df.assignee = df.assignee.str.replace('Corporation','Corp')\n",
        "  df.assignee = df.assignee.str.replace('Incorporated','Inc')\n",
        "  df.assignee = df.assignee.str.upper()\n",
        "  df.drop_duplicates(keep='first', inplace=True)\n",
        "  return df\n",
        "cleanedDF  = cleanupList1Data(df)\n",
        "cleanedDF.to_csv(\"cleanedIndustry.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROuBwYMMpICt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel(\"name matching task - list2.xlsx\")\n",
        "def cleanupList2Data(df):\n",
        "  df.conm = df.conm.str.replace(',','')\n",
        "  df.conm = df.conm.str.replace('.','')\n",
        "  return df\n",
        "list2DF = cleanupList2Data(df)\n",
        "list2DF.to_csv(\"list2clean.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hvu4LsB3pemN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dflist1 = pd.read_csv(\"cleanedIndustry.csv\")\n",
        "dflist2 = pd.read_csv(\"list2clean.csv\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5_ML0cFp2bs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_concat = pd.concat([dflist1.assignee, dflist2.conm]).to_frame()\n",
        "df_concat.drop_duplicates(keep= 'first', inplace = True)\n",
        "df_concat.to_csv(\"concat.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwjJr38AqFEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11eb8aeb-4057-4d12-85bb-d485eaef4ee4"
      },
      "source": [
        "companyNameNotMatched = (df_concat.shape[0]) - (dflist2.shape[0])\n",
        "totalCompanyNametoBeSearched = dflist1.shape[0]\n",
        "accuracy = 100*(totalCompanyNametoBeSearched-companyNameNotMatched)/totalCompanyNametoBeSearched\n",
        "print(\"Accuracy %\",accuracy)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy % 26.985482493595217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc0Ly3F9rDBe",
        "colab_type": "text"
      },
      "source": [
        "**Solution:**Given is a list of business descriptions for around 24,000 companies (provided in the file company descriptions). There are 2 types of descriptions – long and short. Use your discretion while using either. Perform the following tasks using the file:  \n",
        "\n",
        "Classify these companies based on their business descriptions to a only of the industries from the industry labels given (provided in the file: industry labels.xlsx).    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U2Z_13qm0hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel(\"company descriptions.xlsx\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh8ZBdSiLSR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for count, sentence in enumerate(df['company_description']):\n",
        "  if (sentence != sentence):\n",
        "    df.values[count][2] = df.values[count][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AC9ZrLClhel4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_industry = pd.read_excel(\"industry labels.xlsx\")\n",
        "stopwordsList = set(stopwords.words(\"english\"))\n",
        "industry_name = []\n",
        "for industry in df_industry['industry']:\n",
        "    industry_name_split = industry.lower().split()\n",
        "    industry_name_split = [word for word in industry_name_split if not word in stopwordsList]\n",
        "    industry_name.append(\" \".join(industry_name_split))\n",
        "industry_count = df_industry.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhJ6gobFhnD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef9f4d3b-3f30-4505-8704-3d89bfa234fc"
      },
      "source": [
        "industry_count"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w38qIgmJhLrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Labeling based upon maximum string matching\n",
        "labeling_data = []\n",
        "try:\n",
        "    for count, sentence in enumerate(df['company_description']):\n",
        "        loc = 0\n",
        "        maxWordCount = 0\n",
        "        if (sentence != sentence):\n",
        "            labeling_data.append(loc)\n",
        "            continue\n",
        "        split_sentence = sentence.lower().split()\n",
        "        \n",
        "        \n",
        "        for index, industry_words in enumerate(industry_name):\n",
        "            for (i, industry_word) in enumerate(industry_words.split()):\n",
        "                currentWordCount = 0\n",
        "                if(sentence.lower().find(industry_word) != -1):\n",
        "                    currentWordCount = currentWordCount + 1\n",
        "                if(currentWordCount > maxWordCount):\n",
        "                    maxWordCount = currentWordCount \n",
        "                    loc = index\n",
        "        labeling_data.append(loc)\n",
        "except Exception as e:\n",
        "    print(e,count)\n",
        "df['Label'] = labeling_data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Gjrl10hx37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#temp.csv has labelled data\n",
        "df.to_csv(\"temp.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yIgMp0-rq1c",
        "colab_type": "text"
      },
      "source": [
        "**Solutioin:**Given the same set of the companies with their business descriptions, cluster these companies, without using any information from the industry labels. Also, identify ways to calculate the accuracy of the clusters generated. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMj1_y8Rm8Zz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cleaniningText(sentence):\n",
        "    try:\n",
        "        \n",
        "        # Text cleaning\n",
        "        sentence = re.sub(\"[^a-zA-Z]\",\" \",str(sentence))\n",
        "        sentence = re.sub(r\"<br />\", \" \", sentence)\n",
        "        sentence = re.sub(r\"   \", \"\", sentence)\n",
        "        sentence = re.sub(r\"  \", \"\", sentence)\n",
        "        \n",
        "        \n",
        "        \n",
        "        #spliting sentence\n",
        "        split_sentence = sentence.lower().split()\n",
        "        \n",
        "       \n",
        "        \n",
        "        #removing stop words\n",
        "        stopwordsList = set(stopwords.words(\"english\"))\n",
        "        after_removing_stopwords = [word for word in split_sentence if not word in stopwordsList]\n",
        "        \n",
        "        \n",
        "        #Stemming\n",
        "        after_stemming = []\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        for word in after_removing_stopwords:\n",
        "            stemmed_word = stemmer.stem(word)\n",
        "            after_stemming.append(stemmed_word)\n",
        "            \n",
        "       \n",
        "        #Lemmatizing\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        lemmatized = [lemmatizer.lemmatize(word) for word in after_stemming]\n",
        "        \n",
        "    except Exception as e:   \n",
        "        print(e)\n",
        "    \n",
        "    return \" \".join(lemmatized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkgJUmMXm_zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleanedData = []\n",
        "try:\n",
        "    for sentence in df['company_description']:\n",
        "        out = cleaniningText(sentence)\n",
        "        cleanedData.append(out)\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xZiS1SnpEdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "92ba681c-913d-4acb-fcac-a538b94198b1"
      },
      "source": [
        "print(len(cleanedData))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U0xAaKZpIOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DajrKMsgpSFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gu3WRhkpcgu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = tfidf_vectorizer.fit_transform(cleanedData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_C_-EsxpgEP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85a15f64-366e-4704-c7b7-e857a6726624"
      },
      "source": [
        "tfidf.todense().shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19965, 158947)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DGlMuU4sfo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kmeans = KMeans(n_clusters=27,max_iter = 10).fit(tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flGJwCN_uP1f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ac84ca25-404e-41dd-90a0-3376615c9bea"
      },
      "source": [
        "kmeans"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=10,\n",
              "       n_clusters=27, n_init=10, n_jobs=None, precompute_distances='auto',\n",
              "       random_state=None, tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePjhS7-nuRxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8d27e1d-75f7-473a-c292-c8b242b2838f"
      },
      "source": [
        "kmeans.predict(tfidf_vectorizer.transform([df['company_description'][0]]))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYk11oJyIA8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = kmeans.predict(tfidf_vectorizer.transform(df['company_description']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgQ91DpRvQ3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Prediction'] = prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYEsA3aZMdpF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"labeled.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sN5Yt1NOFZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "b0738be3-9ee0-495d-e93a-d3067e4c7a6e"
      },
      "source": [
        "import numpy as np\n",
        "df1 = pd.read_csv(\"labeled.csv\")\n",
        "\n",
        "groupingBasedOnClustering = df1.groupby('Prediction')\n",
        "\n",
        "#Listing Industry classification based upon actual label's for each cluster\n",
        "clusterringOrder = [[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]*industry_count\n",
        "for key, item in groupingBasedOnClustering:\n",
        "    dfForKey = groupingBasedOnClustering.get_group(key)\n",
        "    groupingBasedOnActualLabel = dfForKey.groupby('Label')\n",
        "    order = [0]*industry_count\n",
        "    for actualkey, actualitem in groupingBasedOnClustering:\n",
        "        order[actualkey] = actualitem.shape[0]\n",
        "    clusterringOrder[key] = order\n",
        "\n",
        "#Identify the max value of each Label under each clustered group and marked as my accuracy\n",
        "accuracy = [0]*industry_count \n",
        "for i in range(industry_count):\n",
        "    #print(i)    \n",
        "    loc = -1\n",
        "    maxVal = -1\n",
        "    indexOfCluster = -1\n",
        "    for j in range(industry_count):\n",
        "        temp = np.max(clusterringOrder[j])\n",
        "        if(temp>maxVal):\n",
        "            maxVal = temp\n",
        "            loc = clusterringOrder[j].index(maxVal)\n",
        "            indexOfCluster = j\n",
        "    for k in range(industry_count):\n",
        "        if(len(clusterringOrder[k])>1):\n",
        "            clusterringOrder[k][loc] = 0 \n",
        "    print(\"label:\", loc, \" cluster:\", indexOfCluster, \" maxval:\", maxVal   )\n",
        "    clusterringOrder[indexOfCluster] = [0]\n",
        "    accuracy[loc] = maxVal   \n",
        "print(accuracy)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: 4  cluster: 0  maxval: 13964\n",
            "label: 5  cluster: 1  maxval: 1901\n",
            "label: 14  cluster: 3  maxval: 813\n",
            "label: 11  cluster: 4  maxval: 649\n",
            "label: 3  cluster: 5  maxval: 454\n",
            "label: 25  cluster: 6  maxval: 385\n",
            "label: 20  cluster: 7  maxval: 359\n",
            "label: 6  cluster: 8  maxval: 270\n",
            "label: 23  cluster: 9  maxval: 205\n",
            "label: 18  cluster: 10  maxval: 134\n",
            "label: 24  cluster: 11  maxval: 99\n",
            "label: 26  cluster: 12  maxval: 99\n",
            "label: 22  cluster: 13  maxval: 97\n",
            "label: 16  cluster: 14  maxval: 87\n",
            "label: 1  cluster: 15  maxval: 75\n",
            "label: 12  cluster: 16  maxval: 75\n",
            "label: 19  cluster: 18  maxval: 70\n",
            "label: 21  cluster: 19  maxval: 68\n",
            "label: 10  cluster: 20  maxval: 58\n",
            "label: 8  cluster: 21  maxval: 48\n",
            "label: 15  cluster: 22  maxval: 30\n",
            "label: 13  cluster: 23  maxval: 15\n",
            "label: 0  cluster: 24  maxval: 7\n",
            "label: 7  cluster: 25  maxval: 2\n",
            "label: 9  cluster: 26  maxval: 1\n",
            "label: 0  cluster: 0  maxval: 0\n",
            "label: 0  cluster: 0  maxval: 0\n",
            "[0, 75, 0, 454, 13964, 1901, 270, 2, 48, 1, 58, 649, 75, 15, 813, 30, 87, 0, 134, 70, 359, 68, 97, 205, 99, 385, 99]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X_9zRW4lkpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "333b35f9-7e8b-46cc-8c91-3f83948b1aa1"
      },
      "source": [
        "np.sum(accuracy)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19958"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXpAmskcoEim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0cc3b6b-87e9-4ce8-fd1f-938114ed445c"
      },
      "source": [
        "print(\"accuracy percentage:\",100*np.sum(accuracy)/df.shape[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy percentage: 99.96493864262459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsFjLfqhodhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gGoanIxod5T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}